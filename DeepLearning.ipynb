{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ディープラーニングの実装基礎\n",
    "1. ディープラーニングフレームワークの１つであるKerasの簡単な使い方を学んでみよう\n",
    "1. パラメータをチューニングして、予測精度の変化を確認しよう\n",
    "1. Data Augmentationを追加して、更に予測精度を改善してみよう"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### おまじない"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from skimage import io"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### マスタデータを読み込んでみよう\n",
    "- 今回は[【練習問題】画像ラベリング（10種類）コンペ](https://signate.jp/competitions/133#abstract)に挑戦します\n",
    "- まずは画像データのラベルデータである`train_master.tsv`と`label_master.tsv`及び応募用サンプルファイル`sample_submit.tsv`を読み込みます"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = pd.read_csv(\"train_master.tsv\", sep=\"\\t\")\n",
    "master = pd.read_csv(\"label_master.tsv\", sep=\"\\t\")\n",
    "sample = pd.read_csv(\"sample_submit.tsv\", header=None, sep=\"\\t\")\n",
    "print(labels.shape)\n",
    "print(master.shape)\n",
    "print(sample.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### マスタデータの中身を確認してみよう"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 画像データを読み込んでみよう\n",
    "- `train_images`フォルダと`test_images`フォルダの中にある画像を全て読み込みましょう\n",
    "- ファイルの読み込む順番に気を付けましょう\n",
    "    - 何も考えずにos.listdir関数等で全てのファイル名を取ってきてから読み込むとlabelsデータの順番と不整合になります\n",
    "        - e.g) train_0.jpg, train_1.jpg, train_10.jpg, train_100.jpg ...\n",
    "    - その為、train_imagesからはlabelsデータから1行ずつファイル名（file_name）を取り出しながら読み込みを行います\n",
    "    - test_imagesも同様な理由で、sampleデータから1行ずつファイル名を取り出しながら読み込みを行います\n",
    "- 読み込んだ画像はそれぞれ`train_imgs`と`test_imgs`という変数に代入し、データ型はnumpyのarrayに変換しておきましょう"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_imgs = []\n",
    "for fname in labels[\"file_name\"]:\n",
    "    path = \"./train_images/\" + fname\n",
    "    img = io.imread(path)\n",
    "    train_imgs.append(img)\n",
    "print(type(train_imgs))\n",
    "train_imgs = np.array(train_imgs)\n",
    "print(type(train_imgs), train_imgs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_imgs = []\n",
    "for fname in sample[0]:\n",
    "    path = \"./test_images/\" + fname\n",
    "    img = io.imread(path)\n",
    "    test_imgs.append(img)\n",
    "print(type(test_imgs))\n",
    "test_imgs = np.array(test_imgs)\n",
    "print(type(test_imgs), test_imgs.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 読み込んだ画像を可視化してみよう\n",
    "- 2行5列で読み込んだ画像を表示させましょう\n",
    "- 各画像のtitleには画像に付与されたラベルを付けます\n",
    "    - 手順としては変数labelsからi行目のlabel_idを取り出し、変数masterからlabel_idが一致するlabel_nameを取得します"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,5))\n",
    "for i in range(10):\n",
    "    plt.subplot(2,5,i+1)\n",
    "    target_id = labels.loc[i,\"label_id\"] # target画像のlabel_idを取得\n",
    "    label = master[master[\"label_id\"]==target_id][\"label_name\"].values[0] # masterからlabel_idに対応するlabel_nameを取得\n",
    "    plt.title(label)\n",
    "    plt.imshow(train_imgs[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ラベルの分布を確認しておきましょう"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels[\"label_id\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 画像データの画素値を正規化しておきましょう\n",
    "- DeepLearningで画像を学習させる前準備として画素値を正規化しておきましょう\n",
    "- 現在は画素値の値域が0~255である為、0~1となるように正規化をしておきます\n",
    "- 正規化をすることで、DeepLearningの学習を円滑に行う効果を期待できます"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_imgs = train_imgs / 255\n",
    "test_imgs = test_imgs / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_imgs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 目的変数であるラベルデータをone-hot-encodingしておきましょう\n",
    "- 今回は画像に付与される10種類のラベルを予測する問題です\n",
    "- この場合、モデルの出力は各ラベルに対する確率値となります\n",
    "    - output = [label1の確率, label2の確率, label3の確率, ..., label10の確率]\n",
    "- その為、学習データもこの形に合わせる必要がある為、ラベルデータをone-hot-encodingしましょう\n",
    "    - e.g) label2の場合は[0,1,0,0,0,0,0,0,0,0]とする\n",
    "- one-hot-encodingはkerasのutil.to_categorical関数が便利なので、こちらを利用します"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = labels[\"label_id\"]\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import utils\n",
    "y_categorical = utils.to_categorical(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 学習パラメータの評価の為に、学習データを２つに分割しましょう\n",
    "- モデルのパラメータをチューニングする際には、学習データを構築/検証データに分割するという方策をとります\n",
    "- 構築データでモデルを学習し、学習に利用しなかった検証データを未知データとし、モデルの汎化性能を評価します\n",
    "- numpyではnp.split関数を使うことで、簡単にデータを分割することができます\n",
    "- 具体的には、`np.split(元の配列, [何番目で分割するかの数値])`と記述します\n",
    "    - より詳しくは例えば[こちら](https://note.nkmk.me/python-numpy-split/)を参考にして下さい"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.split([1,2,3,4,5],[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 今回は学習データ5000枚中、4000枚を構築データ、残り1000枚を検証データとします\n",
    "- 構築用画像を`X_tr`、検証用画像を`X_val`としましょう\n",
    "- 同様に、構築用画像のラベルを`y_tr`、検証用画像のラベルを`y_val`としましょう"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr, X_val = np.split(train_imgs,[4000])\n",
    "y_tr, y_val = np.split(y_categorical, [4000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_tr.shape, X_val.shape)\n",
    "print(y_tr.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kerasの使い方の基本を学びましょう\n",
    "- 基本となる使い方は下記となります\n",
    "    1. `model = Sequential()`：モデルの箱を準備する\n",
    "    1. `model.add(XXX)`：add関数の中にモジュールを記述することで、Neural Networkの構造を追加していく\n",
    "    1. `model.compile(loss=\"xxx\", optimizer=\"yyy\", metrics=[\"zzz\"])`：損失関数やオプティマイザー、評価関数等を設定\n",
    "    1. `model.fit(trainX, y, batch_size, epoch, verbose=1, validation_data=(X_val, y_val))`：学習データやbatch_size, epoch等を設定して学習\n",
    "\n",
    "\n",
    "- 今回利用するモジュールは下記です\n",
    "    - Dense(X)：全結合層であり、Xはノード数を表す\n",
    "    - Conv2D（filters=X, kernel_size=(x,x), padding）：畳み込み層であり、Xはフィルタの数、(x,x)はフィルタの大きさを表す\n",
    "    - MaxPooling2D(pool_size=(x,x))：プーリング（max pooling）層であり、(x,x)はプーリング窓の大きさを表す\n",
    "    - Activation(\"xxx\")：活性化関数を表し、xxxに活性化関数（sigmoidやrelu）の前を記述する\n",
    "    - Flatten()：多次元配列を1次元配列に変換する。畳み込み層から全結合層へ接続する際に必要となる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Activation\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import optimizers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 練習で下記構造をKerasで作ってみましょう\n",
    "- Sequentialを使い、モデルの箱を準備し、モデルに層を追加してみましょう"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"MLP.png\" width=\"300\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNNを使って実際に学習をしてみよう"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- model作成部分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(filters=6, kernel_size=(3,3), padding=\"same\", input_shape=(96,96,3)))\n",
    "model.add(Activation(\"sigmoid\"))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Conv2D(filters=12, kernel_size=(3,3), padding=\"same\"))\n",
    "model.add(Activation(\"sigmoid\"))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units=120))\n",
    "model.add(Activation(\"sigmoid\"))\n",
    "model.add(Dense(units=60))\n",
    "model.add(Activation(\"sigmoid\"))\n",
    "model.add(Dense(units=10))\n",
    "model.add(Activation(\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 学習に必要となる損失関数やオプティマイザーと、学習結果の確認の為の評価関数の設定\n",
    "    - SGDの細かいパラメータ詳細については[こちら](https://keras.io/ja/optimizers/)\n",
    "    - lr（学習率）が特に重要なパラメータです"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"categorical_crossentropy\",\n",
    "             optimizer=optimizers.SGD(lr=0.5, momentum=0.9, decay=0.0, nesterov=True),\n",
    "             metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- batch_sizeとepochの設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=100\n",
    "epochs=10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- モデルの学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history = model.fit(X_tr, y_tr,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 学習曲線の可視化してみよう\n",
    "- 損失関数と評価関数の遷移を見ることで、モデルの学習が進んでいるのかや、過学習していないかを確認することができます"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learning_plot(history, epochs):\n",
    "    fig = plt.figure(figsize=(15,5))\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.plot(range(1,epochs+1), history.history['loss'])\n",
    "    plt.plot(range(1,epochs+1), history.history['val_loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.xticks(range(1,epochs+1))\n",
    "    plt.ylabel('loss')\n",
    "    plt.legend(['train', 'val'], loc='upper right')\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.plot(range(1,epochs+1), history.history['acc'])\n",
    "    plt.plot(range(1,epochs+1), history.history['val_acc'])\n",
    "    plt.title('model accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.xticks(range(1,epochs+1))\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.legend(['train', 'val'], loc='upper left')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_plot(history,epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 学習率を0.05にして再度モデルを学習し直してみよう\n",
    "- 学習が進んでいないのは学習率が高すぎる可能性があります"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(filters=6, kernel_size=(3,3), padding=\"same\", input_shape=(96,96,3)))\n",
    "model.add(Activation(\"sigmoid\"))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Conv2D(filters=12, kernel_size=(3,3), padding=\"same\"))\n",
    "model.add(Activation(\"sigmoid\"))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units=120))\n",
    "model.add(Activation(\"sigmoid\"))\n",
    "model.add(Dense(units=60))\n",
    "model.add(Activation(\"sigmoid\"))\n",
    "model.add(Dense(units=10))\n",
    "model.add(Activation(\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"categorical_crossentropy\",\n",
    "             optimizer=optimizers.SGD(lr=0.05, momentum=0.9, decay=0.0, nesterov=True),\n",
    "             metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=100\n",
    "epochs=20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history = model.fit(X_tr, y_tr,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_plot(history,epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 演習①　活性化関数をsigmoidからreluに変換し、学習をし直してみましょう"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 作ったモデルを使い、test_imgsの画像へのラベル予測を行い、SIGNATEに投稿してみましょう\n",
    "- 予測は`model.predict`関数を使います\n",
    "- 予測結果はpred = [label1の確率, label2の確率, ..., label10の確率]と返ってきますが、label_idを1つに決める必要があります\n",
    "- その為、`argmax(axis=1)`関数を使い、一番確率値が高いindexを取得します（indexはlabel_idと一致している為）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(test_imgs)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = pred.argmax(axis=1)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample[1] = pred\n",
    "sample.to_csv(\"submit1.tsv\", sep=\"\\t\", index=None, header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 演習②　今度はオプティマイザーをAdamに変更してモデルを学習し、予測結果をSIGNATEに投稿しましょう\n",
    "- Adamを使う為には、`optimizer.Adam()`と記述します\n",
    "- 投稿ファイルは`submit2.tsv`というファイル名で保存しましょう"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 演習③　層を１つ又は２つ程度追加し、精度を検証してみましょう\n",
    "- 良いパラメータがあれば、SIGNATEにも投稿してみましょう\n",
    "- filtersの値やkernel_sizeの値も変更してみましょう"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 精度の検証をしてみよう\n",
    "- 今回作成したモデルがどんな画像に対して当たっていて、どんな画像を外しているのかを確かめることも重要です\n",
    "- 今回のようにラベル自体を出力結果とする時には混合行列を算出し、確かめることをします\n",
    "- まず、検証用データに対する予測値を求め、sklearnのconfusion_matrix関数を使い、混合行列を求めます"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(X_val)\n",
    "pred = pred.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm = confusion_matrix(y_val.argmax(axis=1), pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 続いて生成したconfusion_matrixを見やすくするためにヒートマップを描きます"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes, title='Confusion Matrix', cmap=plt.cm.Blues):\n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    ax.figure.colorbar(im, ax=ax)\n",
    "    ax.set(xticks=np.arange(cm.shape[1]),\n",
    "           yticks=np.arange(cm.shape[0]))\n",
    "    ax.set_title(title, size=20)\n",
    "    ax.set_ylabel('True label', fontsize=15)\n",
    "    ax.set_xlabel('Predicted label', fontsize=15)\n",
    "    ax.set_xticklabels(classes, fontsize=15)\n",
    "    ax.set_yticklabels(classes, fontsize=15)\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha='right',\n",
    "             rotation_mode='anchor')\n",
    "\n",
    "    fmt = 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(j, i, format(cm[i, j], fmt), fontsize=20,\n",
    "                    ha='center', va='center',\n",
    "                    color='white' if cm[i, j] > thresh else 'black')\n",
    "    fig.tight_layout()\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(cm, master[\"label_name\"].values)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_img(true_label, pred_label,pred,y_val):\n",
    "    tmp = pd.DataFrame({\"pred\":pred,\"true\":y_val.argmax(axis=1)})\n",
    "    tix = master[master[\"label_name\"]==true_label][\"label_id\"].values[0]\n",
    "    pix = master[master[\"label_name\"]==pred_label][\"label_id\"].values[0]\n",
    "    tmp = tmp[(tmp[\"pred\"]==pix)&(tmp[\"true\"]==tix)]\n",
    "    \n",
    "    if tmp.shape[0] > 0:    \n",
    "        n = int(np.ceil(np.sqrt(tmp.shape[0])))\n",
    "        fig = plt.figure(figsize=(n+5,n+5))\n",
    "        fig.subplots_adjust(left=0, right=0.5, bottom=0, top=0.5, hspace=0.05, wspace=0.05)\n",
    "        for i,v in enumerate(tmp.index):\n",
    "            ax = fig.add_subplot(n, n, i + 1, xticks=[], yticks=[])\n",
    "            ax.imshow(X_val[v])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_img(true_label=\"dog\", pred_label=\"cat\", pred=pred, y_val=y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_img(true_label=\"cat\", pred_label=\"dog\", pred=pred, y_val=y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ラベル別の正解率を算出してみよう\n",
    "- confusion_matrixを使えば、ラベル別に正解率を見ることもできます\n",
    "- diagonal関数は対角成分（つまり各ラベルで正解した数）のみを抽出することができます\n",
    "- 従って「ラベルの正解数÷ラベルの総数」により、各ラベルの正解率を求めることができます"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = cm.diagonal()/cm.sum(axis=1)\n",
    "ac1 = pd.DataFrame({\"label\":master[\"label_name\"], \"Accuracy\":acc})\n",
    "ac1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### モデルの保存の仕方とモデルの読み込み方について知ろう\n",
    "- モデルはHDF5というファイルとして保存される為、拡張子は「.h5」とします\n",
    "- 保存は`model.save()`、読み込みは`load_model()`を使います"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'my_model.h5'\n",
    "model.save(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "model = load_model(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ▼更に精度向上を狙い、Data Augmentationを試してみよう\n",
    "- Data Augmentationとはデータを水増しすることで、画像のパターンを増やして汎化性能を上げることを狙った手法を言います\n",
    "- Data Augmentationは学習データに対する水増しと、予測データに対する水増しの2種類あります。\n",
    "    - 後者はtest time augmentation（TTA）と呼ばれます\n",
    "- 今回は前者の学習データに対する水増しの方法を学びましょう"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### kerasのライブラリを使い、データ水増し器を作ろう\n",
    "- scikit-image等を使いデータ水増しをすることもできますが、簡単な画像処理であればkerasに便利なライブラリ「ImageDataGenerator」があります"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ジェネレーターの使い方を学ぼう\n",
    "- 基本的な画像操作の指定方法は下記です（より詳細は[こちら](https://keras.io/ja/preprocessing/image/)）\n",
    "    1. 平行移動：height_shift_rangeとwidth_shift_rangeに平行移動させる割合（0.0-1.0）を設定する\n",
    "    1. 反転：上下ならvertical_flip、左右ならhorizotal_flipをTrueにする\n",
    "    1. 回転：rotation_rangeに最大回転角度の数値を設定する\n",
    "    \n",
    "\n",
    "- ジェネレーターの使い方は下記のようになります\n",
    "    1. 画像操作の内容を指定したジェネレーターを宣言する\n",
    "    1. flow関数を使い、iteratorを作る。その際、batch_sizeの指定が必要"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = train_imgs[1:2,]\n",
    "batch_size = 1\n",
    "\n",
    "# 平行移動\n",
    "g1 = ImageDataGenerator(height_shift_range=0.5, width_shift_range=0.5)\n",
    "i1 = g1.flow(img, batch_size=batch_size)\n",
    "\n",
    "# 左右反転\n",
    "g2 = ImageDataGenerator(horizontal_flip=True)\n",
    "i2 = g2.flow(img, batch_size=batch_size)\n",
    "\n",
    "# 回転\n",
    "g3 = ImageDataGenerator(rotation_range=90)\n",
    "i3 = g3.flow(img, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(3,5,figsize=(10,5))\n",
    "i = 0\n",
    "for a,b,c in zip(i1,i2,i3):\n",
    "    if i > 4:\n",
    "        break\n",
    "    ax[0][i].imshow(a[0])\n",
    "    ax[1][i].imshow(b[0])\n",
    "    ax[2][i].imshow(c[0])\n",
    "    i+=1\n",
    "ax[0][4].text(105,55,\"<- shift images\",fontsize=20)\n",
    "ax[1][4].text(105,55,\"<- flip images\",fontsize=20)\n",
    "ax[2][4].text(105,55,\"<- rotate images\",fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Augmentationを使い、モデルを学習しましょう"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(filters=12, kernel_size=(3,3), padding=\"same\", input_shape=(96,96,3)))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Conv2D(filters=24, kernel_size=(3,3), padding=\"same\"))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Conv2D(filters=36, kernel_size=(3,3), padding=\"same\"))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units=120))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Dense(units=60))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Dense(units=10))\n",
    "model.add(Activation(\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"categorical_crossentropy\",\n",
    "             optimizer=optimizers.Adam(),\n",
    "             metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=100\n",
    "epochs=60"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Data AugumentationのGeneratorを生成\n",
    "    - ここでは`height_shift_range=0.2, width_shift_range=0.2, horizontal_flip=True`とします"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 構築データ用のジェネレーター\n",
    "datagen = ImageDataGenerator(height_shift_range=0.2, width_shift_range=0.2, horizontal_flip=True)\n",
    "iterator = datagen.flow(X_tr, y_tr, batch_size=batch_size)\n",
    "\n",
    "# 検証データ用のジェネレーター（特に何もしない）\n",
    "datagen_val = ImageDataGenerator()\n",
    "iterator_val = datagen_val.flow(X_val, y_val, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Generatorを使い学習をする場合には、fit関数ではなく、fit_generator関数を代わりに使います\n",
    "- この時、steps_per_epochを指定する必要がありますが、これは1epochあたり何ステップ実施するかを意味します\n",
    "    - 通常はデータサイズ÷バッチサイズとします\n",
    "    - batch_size=100ならば、1stepあたり100枚学習に使うことになるので、4000枚の学習画像全てを網羅する為には4000/100=40回必要になる為"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history = model.fit_generator(generator=iterator, \n",
    "                              steps_per_epoch=len(X_tr)/batch_size, \n",
    "                              epochs=epochs, \n",
    "                              validation_data = iterator_val,\n",
    "                              validation_steps = len(X_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_plot(history,epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 精度の検証をしてみよう"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(X_val)\n",
    "pred = pred.argmax(axis=1)\n",
    "cm = confusion_matrix(y_val.argmax(axis=1), pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(cm, master[\"label_name\"].values)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_img(true_label=\"dog\", pred_label=\"cat\", pred=pred, y_val=y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_img(true_label=\"cat\", pred_label=\"dog\", pred=pred, y_val=y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = cm.diagonal()/cm.sum(axis=1)\n",
    "ac2 = pd.DataFrame({\"label\":master[\"label_name\"], \"Accuracy\":acc})\n",
    "ac2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ac1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 応募用ファイルを作り、SIGNATEに投稿してみよう"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(test_imgs)\n",
    "pred = pred.argmax(axis=1)\n",
    "sample[1] = pred\n",
    "sample.to_csv(\"submit4.tsv\", sep=\"\\t\", index=None, header=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
